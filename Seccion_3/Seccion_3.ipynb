{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOUbRRJGUIGxBFnmuMlkbPw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 0.&nbsp;Instalación Spark"],"metadata":{"id":"g1cmZ2oh6DQU"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7BkdiDld1o1Z","executionInfo":{"status":"ok","timestamp":1697556118540,"user_tz":300,"elapsed":1333134,"user":{"displayName":"Andres Felipe Forero Correa","userId":"08763091442910396359"}},"outputId":"cbf6b351-5241-47be-9511-8c5f73e2c838"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.5/281.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["# Instalar SDK Java 8\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","\n","# Descargar Spark 3.2.3\n","!wget -q https://archive.apache.org/dist/spark/spark-3.2.3/spark-3.2.3-bin-hadoop3.2.tgz\n","\n","# Descomprimir el archivo descargado de Spark\n","!tar xf spark-3.2.3-bin-hadoop3.2.tgz\n","\n","# Establecer las variables de entorno\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.3-bin-hadoop3.2\"\n","\n","# Instalar la librería findspark\n","!pip install -q findspark\n","\n","# Instalar pyspark\n","!pip install -q pyspark==3.2.3"]},{"cell_type":"markdown","source":["## 1.&nbsp;Spark Session"],"metadata":{"id":"2nIe88R36xuG"}},{"cell_type":"code","source":["# Find Spark\n","import findspark\n","findspark.init()\n","\n","# Spark Session\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").appName('Curso Pyspark').getOrCreate()\n","spark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"AsnkdT8f6kDC","executionInfo":{"status":"ok","timestamp":1697558190456,"user_tz":300,"elapsed":204,"user":{"displayName":"Andres Felipe Forero Correa","userId":"08763091442910396359"}},"outputId":"3bbb4086-98e4-434d-c954-54042237cc17"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<pyspark.sql.session.SparkSession at 0x787c942bbc70>"],"text/html":["\n","            <div>\n","                <p><b>SparkSession - in-memory</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://4fd20d131362:4040\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.2.3</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>local[*]</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>Curso Pyspark</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["## 2.&nbsp;RDD"],"metadata":{"id":"_pO6fSGTHvc5"}},{"cell_type":"code","source":["# Spark Context\n","sc = spark.sparkContext"],"metadata":{"id":"8S5UKaolIJ5L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Crear un RDD vacío\n","empty_rdd_1 = sc.emptyRDD"],"metadata":{"id":"L5a6BcuKH78A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Crear un RDD vacío con parallelize\n","empty_rdd_2 = sc.parallelize([], 3)\n","empty_rdd_2.getNumPartitions()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MFrQ7U1XIPov","executionInfo":{"status":"ok","timestamp":1697558197382,"user_tz":300,"elapsed":353,"user":{"displayName":"Andres Felipe Forero Correa","userId":"08763091442910396359"}},"outputId":"83c74995-80ec-4bb7-b756-330b55f98d3b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["# Crear un RDD no vacío con parallelize\n","rdd_1 = sc.parallelize([1, 2, 3, 4, 5])\n","rdd_1.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_STdZPppIljh","executionInfo":{"status":"ok","timestamp":1697558198222,"user_tz":300,"elapsed":4,"user":{"displayName":"Andres Felipe Forero Correa","userId":"08763091442910396359"}},"outputId":"5a203280-3acf-435c-9e28-b3f95b048b86"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 3, 4, 5]"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["# Crear un RDD desde un archivo de texto como una lista de lineas de texto\n","text_file_rdd_1 = sc.textFile('./rdd_source.txt')\n","text_file_rdd_1.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6ujqtOlIIxyn","executionInfo":{"status":"ok","timestamp":1697558199950,"user_tz":300,"elapsed":633,"user":{"displayName":"Andres Felipe Forero Correa","userId":"08763091442910396359"}},"outputId":"ce0422e8-0163-4813-8cc7-e72a37d2c24d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Así podemos crear', 'un RDD desde un', 'archivo de texto!!!']"]},"metadata":{},"execution_count":46}]},{"cell_type":"code","source":["# Crear un RDD desde un archivo texto como un simple registro\n","text_file_rdd_2 = sc.wholeTextFiles('./rdd_source.txt')\n","text_file_rdd_2.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fP6WvXHYKFD1","executionInfo":{"status":"ok","timestamp":1697558200891,"user_tz":300,"elapsed":181,"user":{"displayName":"Andres Felipe Forero Correa","userId":"08763091442910396359"}},"outputId":"f544bc21-0d1c-4d1c-a3fc-2cfcd50a55d2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('file:/content/rdd_source.txt',\n","  'Así podemos crear\\nun RDD desde un\\narchivo de texto!!!')]"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["# Crear un RDD desde otro RDD\n","sum_rdd = rdd_1.map(lambda x: x + 1)\n","sum_rdd.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rX4s7Z7PK09M","executionInfo":{"status":"ok","timestamp":1697558202385,"user_tz":300,"elapsed":213,"user":{"displayName":"Andres Felipe Forero Correa","userId":"08763091442910396359"}},"outputId":"f44b096d-76d6-4a52-99eb-49d2d45e0ac6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[2, 3, 4, 5, 6]"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["# Crear un RDD desde un Dataframe\n","df = spark.createDataFrame([(1, 'jose'), (2, 'juan')], ['id', 'nombre'])\n","df_rdd = df.rdd\n","df_rdd.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gReAQnhMLICY","executionInfo":{"status":"ok","timestamp":1697558203646,"user_tz":300,"elapsed":509,"user":{"displayName":"Andres Felipe Forero Correa","userId":"08763091442910396359"}},"outputId":"3d044437-59e3-45cf-f4e0-85c44aa4162a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(id=1, nombre='jose'), Row(id=2, nombre='juan')]"]},"metadata":{},"execution_count":49}]}]}